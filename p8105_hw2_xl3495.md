p8105_hw2_xl3495
================
Xueting Li
2024-09-30

``` r
library(tidyverse)
library(readxl)
library(haven)
```

# Problem 1

``` r
nyc_subway_df = 
  read_csv("datasets/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA",".","")) |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) |>
  mutate(
    entry = case_match(
    entry,
    "YES" ~ TRUE,
    "NO" ~ FALSE)
)

head(nyc_subway_df)
```

    ## # A tibble: 6 × 19
    ##   line     station_name station_latitude station_longitude route1 route2 route3
    ##   <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ## 1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entrance_type <chr>, entry <lgl>, vending <chr>, ada <lgl>

## Description

So far, the dataset contains 19 variables:

`line`: `<chr>`, describes the line setting;  
`station_name`: `<chr>`, describes the name of the station;  
`station_latitude` & `station_longitude`: `<dbl>`, describe the location
of the station;  
`route1`–`route11`: `<chr>`, describe how many and what routes are going
to pass the station;  
`entrance_type`: `<chr>`, describes the way to enter;  
`entry`: `<lgl>`, describes whether the entry is in use;  
`vending`: `<chr>`, describes whether there is a vending machine;  
`ada`: `<lgl>`, describes whether there is an ADA compliance.

I cleaned this dataset by 4 steps so far.  
1. Read the dataset and substitute all possible blank values using `NA`.
2. Convert all variable names to lowercase with underline substituting
blank space. 3. Select all required columns using `select()` function.
4. Inside `mutate()` function, convert `entry` variable type from
`<chr>` to `<lgl>` by setting ‘YES’ to `TRUE`, ‘NO’ to `FALSE` using
`case_match()` function.

``` r
col = ncol(nyc_subway_df)
row = nrow(nyc_subway_df)
```

Now the dataset is cleaned to 1868 . But it’s not tidy enough since
there exists some repeated rows and columns from `route1` to `route11`
are multifarious and redundant to read.

``` r
num_stations = nyc_subway_df |>
  distinct(line, station_name) |>
  nrow()

num_ada = nyc_subway_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()

num_entrance = nyc_subway_df |>
  filter(vending == "NO") |>
  filter(entry == TRUE) |>
  distinct(line, station_name) |>
  nrow()

proportion_entrance = num_entrance/num_stations*100
proportion_entrance = paste(round(proportion_entrance, 2), "%")
```

In total, there are 465 distinct stations, and 84 of them are ADA
compliant, and 9.25 % of station entrances / exits without vending allow
entrance.

``` r
A_df = nyc_subway_df |>
  mutate(
    across(route1:route11, ~ as.character(.))
  ) |>
  pivot_longer(cols = route1:route11,
                    names_to = "route_names",
                    values_to = "route_numbers") |>
  filter(route_numbers == "A")
  
num_A_stations = A_df |>
  distinct(line, station_name) |>
  nrow()

num_A_ada = A_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

From above, 60 distinct stations serve the A train. Of the stations that
serve the A train, 17 are ADA compliant.

# Problem 2

``` r
trash_wheel_df = 
  read_excel("datasets/202409\ Trash\ Wheel\ Collection\ Data.xlsx", sheet = "Mr. Trash Wheel" , skip = 1, n_max = 651) |>
  janitor::clean_names() |>
  filter(is.na(dumpster) == FALSE) |>
  mutate(
    sports_balls = round(sports_balls) |>
      as.integer()
  )
```

``` r
prof_trash_wheel_df = 
  read_excel("datasets/202409\ Trash\ Wheel\ Collection\ Data.xlsx", sheet = "Professor Trash Wheel" , skip = 1, n_max = 118) |>
  janitor::clean_names() |>
  filter(is.na(dumpster) == FALSE)

gwynnda_trash_wheel_df = 
  read_excel("datasets/202409\ Trash\ Wheel\ Collection\ Data.xlsx", sheet = "Gwynnda Trash Wheel" , skip = 1, n_max = 264) |>
  janitor::clean_names() |>
  filter(is.na(dumpster) == FALSE)

mr_df = trash_wheel_df |>
  mutate(trash_wheel = 
           paste("mr", as.character(dumpster), sep = "_")) |>
  mutate(year = as.double(year)) |>
  relocate(trash_wheel) |>
  select(-dumpster)

prof_df = prof_trash_wheel_df |> 
  mutate(trash_wheel = 
           paste("prof", as.character(dumpster), sep = "_")) |>
  relocate(trash_wheel) |>
  select(-dumpster)

gwynnda_df = gwynnda_trash_wheel_df |>
  mutate(trash_wheel = 
           paste("gwynnda", as.character(dumpster), sep = "_")) |>
  relocate(trash_wheel) |>
  select(-dumpster)

combined_df = bind_rows(mr_df, prof_df, gwynnda_df) |>
  select(-month, -year, -x15, -x16)

size = nrow(combined_df)

head(combined_df)
```

    ## # A tibble: 6 × 12
    ##   trash_wheel date                weight_tons volume_cubic_yards plastic_bottles
    ##   <chr>       <dttm>                    <dbl>              <dbl>           <dbl>
    ## 1 mr_1        2014-05-16 00:00:00        4.31                 18            1450
    ## 2 mr_2        2014-05-16 00:00:00        2.74                 13            1120
    ## 3 mr_3        2014-05-16 00:00:00        3.45                 15            2450
    ## 4 mr_4        2014-05-17 00:00:00        3.1                  15            2380
    ## 5 mr_5        2014-05-17 00:00:00        4.06                 18             980
    ## 6 mr_6        2014-05-20 00:00:00        2.71                 13            1430
    ## # ℹ 7 more variables: polystyrene <dbl>, cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>

## Description

In total, there are 1032 observations of data. This combined dataframe
contains three kinds of `trash_wheel`s, which are obtained from
`Mr._Trash_Wheel` (mr\_), `Professor_Trash_Wheel` (prof\_),
`Gwynnda_Trash_Wheel` (gwynnda\_), and after the underline is the
machine number of each kind of Trash Wheel. I deleted `month` and `year`
and preserved `date` to show the time of data collected. There are
several variables describe the general ability of each trash wheel,
including how many tons of trash it has handled, how much space of these
trash take. Remaining variables like `plastic_bottles`, `polystyrene`
etc. are trash types.`homes_powered` shows how much energy it consumed
(not sure). I also removed the `x15` and `x16` column since they contain
no values, showing `NA`.  
Take the first row as an example, `Mr. Trash Wheel -- dumpster 1` has
dealt with 4.31 tons of trash until 2014-05-16, which takes 18 cubic
yards. Among the trash, 1450 are plastic bottles, 72 are glass bottles,
etc (here I didn’t include all trash types). No power was recorded.

``` r
prof_weight_trash = prof_df |>
  pull(weight_tons) |>
  sum(na.rm = TRUE)

num_gwynnda_cigarette = 
  gwynnda_trash_wheel_df |>
  filter(month == "June", year == "2022") |>
  pull(cigarette_butts) |>
  sum(na.rm = TRUE)
```

From above, the total weight of trash collected by Professor Trash Wheel
is 246.74. The total number of cigarette butts collected by Gwynnda in
June of 2022 is 1.812^{4}.

# Problem 3

``` r
gbb_bakers = read_csv("datasets/bakers.csv", na = c("N/A",".","")) |>
  janitor::clean_names() |>
  mutate(
    baker = sub(" .*", "", baker_name)) |>
  relocate(baker, baker_name) |>
  arrange(series)

gbb_bakes = read_csv("datasets/bakes.csv", na = c("N/A","UNKNOWN","")) |>
  janitor::clean_names() |>
  arrange(series, episode)

gbb_results = read_csv("datasets/results.csv", na = c("NA",".",""), skip = 2) |>
  janitor::clean_names() |>
  arrange(series, episode)

test_df_1 = anti_join(gbb_bakes, gbb_results)
test_df_2 = anti_join(gbb_results, gbb_bakes)
test_df_3 = anti_join(gbb_bakers, gbb_bakes)
test_df_4 = anti_join(gbb_bakes, gbb_bakers)

test_df_5 = gbb_bakes |>
  filter(baker == "\"Jo\"")

gbb_bakes = gbb_bakes |>
  mutate(baker = if_else(baker == "\"Jo\"", "Jo", baker))



bake_result_df = full_join(gbb_bakes, gbb_results, by = c("baker", "series", "episode"))

#check if there is an unknown person
num_unknown = bake_result_df |>
  filter(is.na(baker)==TRUE) |>
  nrow()

# evaluate the duplicates
duplicate_bakers = bake_result_df |>
  group_by(baker, series, episode) |>
  filter(n() > 1) |>
  nrow()

final_df = full_join(gbb_bakers, bake_result_df, by = c("baker", "series")) |>
  select(-baker) |>
  relocate(series, .before = episode) |>
  filter((is.na(result)==FALSE) | (baker_name == "Jo Wheatley"))
```

## Cleaning Process

**First**, I read three `csv` documents and in order to inspect if they
have shared common variables to combine, I converted their variable
names into lowercase with underlines in `gbb_bakers`, `gbb_bakes`,
`gbb_results`. Then the similar columns I found are:  
`gbb_bakers`: `baker_name`, `series`;  
`gbb_bakes`: `baker`, `series`, `episode` (shared with only
`gbb_results`);  
`gbb_results`: `baker`, `series`, `episode`.  
One thing needs to be specific is that in the `results.csv` document,
there are some notes for variable explanations, so I skipped the first
two lines. And looking at these original `csv` files, I found their `na`
values are not consistent, so I made the all `NA` when read.

**Second**, I noticed that although the columns I found are similar,
there still exist some differences. For specific, in `gbb_bakers`,
bakers are recorded by their full names, while they are called by their
first name in the other two. So I used `mutate()` function to add a new
column called `baker` in `gbb_bakers` dataframe to record their first
names, which was extracted by `sub()` function. But `baker_name` was
still preserved for complete information of full names. Here, I also
reordered the three dataframes in the order of `series` and `episode`
for convenience in comparing if the observation matched each other.

Here, a strange person called **Jo Wheatley** appears. This was found by
`anti_join()` function with my 5 `test_df_`s. She has her name on
`bakers.csv` and mistakenly put a `""` sign on `bakes.csv`. On
`bakes.csv`, it shows that she made through 8 episodes and clearly
recorded the bakery’s name, but the information of her results turned
out to be missing. I guess she has survived through Series 2, otherwise
there would not be a record for her bakeries. So, I only revised the
name in `gbb_bakes` by `mutate()` function and kept all information
using `full_join()` function, which will be explained below.

**Third**, since the `gbb_bakes` and `gbb_results` have same variables:
`baker`, `series`, `episode`, I tried to combine them first. And to
preserve as much information as possible, I chose the `full_join()`
function here to keep all information for each observation.

``` r
head(bake_result_df, 10)
```

    ## # A tibble: 10 × 7
    ##    series episode baker     signature_bake         show_stopper technical result
    ##     <dbl>   <dbl> <chr>     <chr>                  <chr>            <dbl> <chr> 
    ##  1      1       1 Annetha   "Light Jamaican Black… Red, White …         2 IN    
    ##  2      1       1 David     "Chocolate Orange Cak… Black Fores…         3 IN    
    ##  3      1       1 Edd       "Caramel Cinnamon and… <NA>                 1 IN    
    ##  4      1       1 Jasminder "Fresh Mango and Pass… <NA>                NA IN    
    ##  5      1       1 Jonathan  "Carrot Cake with Lim… Three Tiere…         9 IN    
    ##  6      1       1 Lea       "Cranberry and Pistac… Raspberries…        10 OUT   
    ##  7      1       1 Louise    "Carrot and Orange Ca… Never Fail …        NA IN    
    ##  8      1       1 Mark      "Sticky Marmalade Tea… Heart-shape…        NA OUT   
    ##  9      1       1 Miranda   "Triple Layered Brown… Three Tiere…         8 IN    
    ## 10      1       1 Ruth      "Three Tiered Lemon D… Classic Cho…        NA IN

To check if there is a person has no name recorded, I introduced
`num_unknown` by `filter()` function to find if there is an `NA` value,
and it turns out to be 0. To check if there is a duplicated observation
for the same individual, I used `groupby()` function to check if there
is a person appeared in the same series and same episode but different
observations, and it also turned out to be 0.

**Finally and similarly**, I applied `full_join()` function to
`gbb_bakers` and `bake_result_df`. Since the information of first name
is included in `baker_name`, I deleted the column `baker` I used for
combination and used `relocate()` function to make the dataframe more
readable. Furthermore, I found that if a person’s result is `"OUT"`,
there won’t be any information in the next few episodes. So, I used
`filter()` function to choose those observations with a `non-NA` result
value. What is interesting is that **Jo Wheatley** has no results but
for reasons above I want to keep it, so I filter her out as well. The
final dataframe is like:

``` r
head(final_df, 10)
```

    ## # A tibble: 10 × 10
    ##    baker_name  baker_age baker_occupation hometown series episode signature_bake
    ##    <chr>           <dbl> <chr>            <chr>     <dbl>   <dbl> <chr>         
    ##  1 Annetha Mi…        30 Midwife          Essex         1       1 Light Jamaica…
    ##  2 Annetha Mi…        30 Midwife          Essex         1       2 Rose Petal Sh…
    ##  3 David Cham…        31 Entrepreneur     Milton …      1       1 Chocolate Ora…
    ##  4 David Cham…        31 Entrepreneur     Milton …      1       2 Cheddar Chees…
    ##  5 David Cham…        31 Entrepreneur     Milton …      1       3 Chilli Bread  
    ##  6 David Cham…        31 Entrepreneur     Milton …      1       4 Pear and Waln…
    ##  7 Edd Kimber         24 Debt collector … Bradford      1       1 Caramel Cinna…
    ##  8 Edd Kimber         24 Debt collector … Bradford      1       2 Oatmeal Raisi…
    ##  9 Edd Kimber         24 Debt collector … Bradford      1       3 Olive Bread   
    ## 10 Edd Kimber         24 Debt collector … Bradford      1       4 Apple and Plu…
    ## # ℹ 3 more variables: show_stopper <chr>, technical <dbl>, result <chr>

## Description

According to the final dataframe, all participants with at least one
episode survived were kept. There are 718 observations in total. Each
observation records the `baker_name`, `baker_age`, `baker_occupation`,
`hometown`, and for each `series` and `episode`, what bakery the baker
made (`signature_bake`,`show_stopper`) with the `technical` level and
`result`.

## Table

``` r
tbl_df = final_df |>
  filter((series >= 5) & 
           (series <= 10) & 
           ((result == "STAR BAKER")|(result == "WINNER"))
            ) |>
  select(baker_name, series, episode, result) |>
  arrange(series, episode)

tbl = as_tibble(tbl_df)
tbl
```

    ## # A tibble: 60 × 4
    ##    baker_name        series episode result    
    ##    <chr>              <dbl>   <dbl> <chr>     
    ##  1 Nancy Birtwhistle      5       1 STAR BAKER
    ##  2 Richard Burr           5       2 STAR BAKER
    ##  3 Luis Troyano           5       3 STAR BAKER
    ##  4 Richard Burr           5       4 STAR BAKER
    ##  5 Kate Henry             5       5 STAR BAKER
    ##  6 Chetna Makan           5       6 STAR BAKER
    ##  7 Richard Burr           5       7 STAR BAKER
    ##  8 Richard Burr           5       8 STAR BAKER
    ##  9 Richard Burr           5       9 STAR BAKER
    ## 10 Nancy Birtwhistle      5      10 WINNER    
    ## # ℹ 50 more rows

For series 6, 7, 8, 9, the winners are predictable since each winner had
won at least two `STAR BAKER`s before among past 9 episodes. And for
series 5 and 10, especially 10, the winner is surprising because Nancy
in Series 5 won only one `STAR BAKER` and David in Series 10 had never
won any `STAR BAKER`s in the past 9 episodes and became `WINNER`
finally!

## Viewers

``` r
gbb_viewers = read_csv("datasets/viewers.csv", na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(
    series_5 = round(series_5, 2)
  )

head(gbb_viewers, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
mean_1 = gbb_viewers |>
  pull(series_1) |>
  mean()

mean_5 = gbb_viewers |>
  pull(series_5) |>
  mean()
```

The average viewership in Season 1 is NA. The average viewership in
Season 5 is 10.039
